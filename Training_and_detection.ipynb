{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed18d3c",
   "metadata": {},
   "source": [
    "# Setting Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "710ae047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f955b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'new_model' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cb0c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('project_images', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('project_images','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('project_images','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('project_images', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('project_images', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('project_images', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('project_images', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('project_images', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('project_images', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('project_images', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('project_images', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('project_images','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69e65cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WORKSPACE_PATH': 'project_images\\\\workspace',\n",
       " 'SCRIPTS_PATH': 'project_images\\\\scripts',\n",
       " 'APIMODEL_PATH': 'project_images\\\\models',\n",
       " 'ANNOTATION_PATH': 'project_images\\\\workspace\\\\annotations',\n",
       " 'IMAGE_PATH': 'project_images\\\\workspace\\\\images',\n",
       " 'MODEL_PATH': 'project_images\\\\workspace\\\\models',\n",
       " 'PRETRAINED_MODEL_PATH': 'project_images\\\\workspace\\\\pre-trained-models',\n",
       " 'CHECKPOINT_PATH': 'project_images\\\\workspace\\\\models\\\\my_ssd_mobnet',\n",
       " 'OUTPUT_PATH': 'project_images\\\\workspace\\\\models\\\\my_ssd_mobnet\\\\export',\n",
       " 'TFJS_PATH': 'project_images\\\\workspace\\\\models\\\\my_ssd_mobnet\\\\tfjsexport',\n",
       " 'TFLITE_PATH': 'project_images\\\\workspace\\\\models\\\\my_ssd_mobnet\\\\tfliteexport',\n",
       " 'PROTOC_PATH': 'project_images\\\\protoc'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68577d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('project_images', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c06fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c1a9ac",
   "metadata": {},
   "source": [
    "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba1faf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\saurabh_maurya\\envs\\odwtf\\lib\\site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "if os.name=='nt':\n",
    "    !pip install wget\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21ec5988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'project_images\\models'...\n",
      "Updating files:  19% (468/2407)\n",
      "Updating files:  20% (482/2407)\n",
      "Updating files:  21% (506/2407)\n",
      "Updating files:  22% (530/2407)\n",
      "Updating files:  23% (554/2407)\n",
      "Updating files:  24% (578/2407)\n",
      "Updating files:  25% (602/2407)\n",
      "Updating files:  26% (626/2407)\n",
      "Updating files:  27% (650/2407)\n",
      "Updating files:  28% (674/2407)\n",
      "Updating files:  29% (699/2407)\n",
      "Updating files:  30% (723/2407)\n",
      "Updating files:  31% (747/2407)\n",
      "Updating files:  32% (771/2407)\n",
      "Updating files:  33% (795/2407)\n",
      "Updating files:  34% (819/2407)\n",
      "Updating files:  35% (843/2407)\n",
      "Updating files:  36% (867/2407)\n",
      "Updating files:  36% (874/2407)\n",
      "Updating files:  37% (891/2407)\n",
      "Updating files:  38% (915/2407)\n",
      "Updating files:  39% (939/2407)\n",
      "Updating files:  40% (963/2407)\n",
      "Updating files:  41% (987/2407)\n",
      "Updating files:  42% (1011/2407)\n",
      "Updating files:  43% (1036/2407)\n",
      "Updating files:  44% (1060/2407)\n",
      "Updating files:  45% (1084/2407)\n",
      "Updating files:  46% (1108/2407)\n",
      "Updating files:  47% (1132/2407)\n",
      "Updating files:  48% (1156/2407)\n",
      "Updating files:  49% (1180/2407)\n",
      "Updating files:  50% (1204/2407)\n",
      "Updating files:  51% (1228/2407)\n",
      "Updating files:  52% (1252/2407)\n",
      "Updating files:  53% (1276/2407)\n",
      "Updating files:  54% (1300/2407)\n",
      "Updating files:  55% (1324/2407)\n",
      "Updating files:  56% (1348/2407)\n",
      "Updating files:  57% (1372/2407)\n",
      "Updating files:  58% (1397/2407)\n",
      "Updating files:  59% (1421/2407)\n",
      "Updating files:  60% (1445/2407)\n",
      "Updating files:  61% (1469/2407)\n",
      "Updating files:  62% (1493/2407)\n",
      "Updating files:  63% (1517/2407)\n",
      "Updating files:  64% (1541/2407)\n",
      "Updating files:  65% (1565/2407)\n",
      "Updating files:  66% (1589/2407)\n",
      "Updating files:  67% (1613/2407)\n",
      "Updating files:  68% (1637/2407)\n",
      "Updating files:  69% (1661/2407)\n",
      "Updating files:  70% (1685/2407)\n",
      "Updating files:  71% (1709/2407)\n",
      "Updating files:  72% (1734/2407)\n",
      "Updating files:  73% (1758/2407)\n",
      "Updating files:  74% (1782/2407)\n",
      "Updating files:  75% (1806/2407)\n",
      "Updating files:  76% (1830/2407)\n",
      "Updating files:  77% (1854/2407)\n",
      "Updating files:  78% (1878/2407)\n",
      "Updating files:  79% (1902/2407)\n",
      "Updating files:  80% (1926/2407)\n",
      "Updating files:  81% (1950/2407)\n",
      "Updating files:  82% (1974/2407)\n",
      "Updating files:  83% (1998/2407)\n",
      "Updating files:  84% (2022/2407)\n",
      "Updating files:  85% (2046/2407)\n",
      "Updating files:  86% (2071/2407)\n",
      "Updating files:  87% (2095/2407)\n",
      "Updating files:  88% (2119/2407)\n",
      "Updating files:  89% (2143/2407)\n",
      "Updating files:  89% (2152/2407)\n",
      "Updating files:  90% (2167/2407)\n",
      "Updating files:  91% (2191/2407)\n",
      "Updating files:  92% (2215/2407)\n",
      "Updating files:  93% (2239/2407)\n",
      "Updating files:  93% (2262/2407)\n",
      "Updating files:  94% (2263/2407)\n",
      "Updating files:  95% (2287/2407)\n",
      "Updating files:  96% (2311/2407)\n",
      "Updating files:  97% (2335/2407)\n",
      "Updating files:  98% (2359/2407)\n",
      "Updating files:  99% (2383/2407)\n",
      "Updating files: 100% (2407/2407)\n",
      "Updating files: 100% (2407/2407), done.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "670e3e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'protoc' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/Saurabh_Maurya/Envs/odwtf/project_images/models/research/slim\n",
      "Requirement already satisfied: six in c:\\users\\saurabh_maurya\\envs\\odwtf\\lib\\site-packages (from slim==0.1) (1.15.0)\n",
      "Requirement already satisfied: tf-slim>=1.1 in c:\\users\\saurabh_maurya\\envs\\odwtf\\lib\\site-packages (from slim==0.1) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in c:\\users\\saurabh_maurya\\envs\\odwtf\\lib\\site-packages (from tf-slim>=1.1->slim==0.1) (0.12.0)\n",
      "Installing collected packages: slim\n",
      "  Attempting uninstall: slim\n",
      "    Found existing installation: slim 0.1\n",
      "    Uninstalling slim-0.1:\n",
      "      Successfully uninstalled slim-0.1\n",
      "  Running setup.py develop for slim\n",
      "Successfully installed slim-0.1\n"
     ]
    }
   ],
   "source": [
    "# Install Tensorflow Object Detection \n",
    "if os.name=='posix':  \n",
    "    !apt-get install protobuf-compiler\n",
    "    !cd project_images/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "   # url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "   # wget.download(url)\n",
    "   # !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "   # !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd project_images/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd project_images/models/research/slim && pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b9ec160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"project_images\\models\\research\\object_detection\\builders\\model_builder_tf2_test.py\", line 24, in <module>\n",
      "    from object_detection.builders import model_builder\n",
      "ModuleNotFoundError: No module named 'object_detection'\n",
      "2021-05-06 21:12:28.785474: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_100.dll'; dlerror: cudart64_100.dll not found\n",
      "2021-05-06 21:12:28.785474: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c6534",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8ac8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall protobuf matplotlib -y\n",
    "!pip install protobuf matplotlib==3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70f6359e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'object_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1a19769998a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'"
     ]
    }
   ],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c8814f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package              Version   Location\n",
      "-------------------- --------- ----------------------------------------------------------------------\n",
      "absl-py              0.12.0\n",
      "anyio                2.2.0\n",
      "argon2-cffi          20.1.0\n",
      "astor                0.8.1\n",
      "async-generator      1.10\n",
      "attrs                20.3.0\n",
      "Babel                2.9.1\n",
      "backcall             0.2.0\n",
      "bleach               3.3.0\n",
      "certifi              2020.12.5\n",
      "cffi                 1.14.5\n",
      "chardet              4.0.0\n",
      "colorama             0.4.4\n",
      "cycler               0.10.0\n",
      "Cython               0.29.23\n",
      "decorator            5.0.7\n",
      "defusedxml           0.7.1\n",
      "deprecation          2.1.0\n",
      "entrypoints          0.3\n",
      "gast                 0.2.2\n",
      "google-pasta         0.2.0\n",
      "grpcio               1.37.1\n",
      "h5py                 2.10.0\n",
      "idna                 2.10\n",
      "importlib-metadata   4.0.1\n",
      "ipykernel            5.5.3\n",
      "ipython              7.23.0\n",
      "ipython-genutils     0.2.0\n",
      "ipywidgets           7.6.3\n",
      "jedi                 0.18.0\n",
      "Jinja2               2.11.3\n",
      "json5                0.9.5\n",
      "jsonschema           3.2.0\n",
      "jupyter-client       6.2.0\n",
      "jupyter-console      6.4.0\n",
      "jupyter-core         4.7.1\n",
      "jupyter-packaging    0.9.2\n",
      "jupyter-server       1.6.4\n",
      "jupyterlab           3.0.14\n",
      "jupyterlab-pygments  0.1.2\n",
      "jupyterlab-server    2.5.0\n",
      "jupyterlab-widgets   1.0.0\n",
      "Keras-Applications   1.0.8\n",
      "Keras-Preprocessing  1.1.2\n",
      "kiwisolver           1.3.1\n",
      "lxml                 4.6.3\n",
      "Markdown             3.3.4\n",
      "MarkupSafe           1.1.1\n",
      "matplotlib           3.1.1\n",
      "matplotlib-inline    0.1.2\n",
      "mistune              0.8.4\n",
      "nbclassic            0.2.7\n",
      "nbclient             0.5.3\n",
      "nbconvert            6.0.7\n",
      "nbformat             5.1.3\n",
      "nest-asyncio         1.5.1\n",
      "notebook             6.3.0\n",
      "numpy                1.20.2\n",
      "opencv-python        4.5.1.48\n",
      "opt-einsum           3.3.0\n",
      "packaging            20.9\n",
      "pandocfilters        1.4.3\n",
      "parso                0.8.2\n",
      "pickleshare          0.7.5\n",
      "Pillow               8.2.0\n",
      "pip                  21.1.1\n",
      "prometheus-client    0.10.1\n",
      "prompt-toolkit       3.0.18\n",
      "protobuf             3.15.8\n",
      "pycparser            2.20\n",
      "Pygments             2.8.1\n",
      "pyparsing            2.4.7\n",
      "PyQt5                5.15.4\n",
      "PyQt5-Qt5            5.15.2\n",
      "PyQt5-sip            12.8.1\n",
      "pyrsistent           0.17.3\n",
      "python-dateutil      2.8.1\n",
      "pytz                 2021.1\n",
      "pywin32              300\n",
      "pywinpty             1.0.1\n",
      "pyzmq                22.0.3\n",
      "qtconsole            5.0.3\n",
      "QtPy                 1.9.0\n",
      "requests             2.25.1\n",
      "Send2Trash           1.5.0\n",
      "setuptools           56.0.0\n",
      "six                  1.15.0\n",
      "slim                 0.1       c:\\users\\saurabh_maurya\\envs\\odwtf\\project_images\\models\\research\\slim\n",
      "sniffio              1.2.0\n",
      "tensorboard          1.15.0\n",
      "tensorflow-estimator 1.15.1\n",
      "tensorflow-gpu       1.15.5\n",
      "termcolor            1.1.0\n",
      "terminado            0.9.4\n",
      "testpath             0.4.4\n",
      "tf-slim              1.1.0\n",
      "tfnets               0.6.0\n",
      "tk                   0.1.0\n",
      "tomlkit              0.7.0\n",
      "tornado              6.1\n",
      "traitlets            5.0.5\n",
      "typing-extensions    3.7.4.3\n",
      "urllib3              1.26.4\n",
      "wcwidth              0.2.5\n",
      "webencodings         0.5.1\n",
      "Werkzeug             1.0.1\n",
      "wget                 3.2\n",
      "wheel                0.36.2\n",
      "widgetsnbextension   3.5.1\n",
      "wrapt                1.12.1\n",
      "zipp                 3.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eebbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8560ce92",
   "metadata": {},
   "source": [
    "# 2. Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "206a5b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'','id':1},\n",
    "         {'name':'','id':2},\n",
    "         {'name':'','id':3},\n",
    "         {'name':'','id':4},\n",
    "         {'name':'','id':5},\n",
    "         {'name':'','id':6},\n",
    "         {'name':'','id':7},\n",
    "         {'name':'','id':8},\n",
    "         {'name':'','id':9},\n",
    "         {'name':'','id':10},\n",
    "         {'name':'','id':11},\n",
    "         {'name':'','id':12},\n",
    "         {'name':'','id':13},\n",
    "         {'name':'','id':14},\n",
    "         {'name':'','id':15},\n",
    "         {'name':'','id':16},\n",
    "         {'name':'','id':17},\n",
    "         {'name':'','id':18},\n",
    "         {'name':'','id':19},\n",
    "         {'name':'','id':20},\n",
    "         {'name':'','id':21},\n",
    "         {'name':'','id':22},\n",
    "         {'name':'','id':23},\n",
    "         {'name':'','id':24},]\n",
    "with open(files['LABELMAP'],'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item {\\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad7b25",
   "metadata": {},
   "source": [
    "# Create TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcc2105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL IF RUNNING ON COLAB\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d588e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e73f78",
   "metadata": {},
   "source": [
    "# 4. Copy Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f5a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3208484",
   "metadata": {},
   "source": [
    "# 5. Update Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ad2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4c7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba060fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4390d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d3fd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4 \n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a60e530",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc2a0cd",
   "metadata": {},
   "source": [
    "# 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4a802",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f4af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a2d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa8d6ee",
   "metadata": {},
   "source": [
    "# 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f0704",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a47e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7128a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72b1b3e",
   "metadata": {},
   "source": [
    "# 8. Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba374af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182fd286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-5')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c660b0",
   "metadata": {},
   "source": [
    "# 9. Detect from an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8415b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef37541",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85693842",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'livelong.02533422-940e-11eb-9dbd-5cf3709bbcc6.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a726b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff309f92",
   "metadata": {},
   "source": [
    "# 10. Real Time Detections from your Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4666c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall opencv-python-headless -y  #not to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a11f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf52a369",
   "metadata": {},
   "source": [
    "# 10. Freezing the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aaae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f7e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(\n",
    "FREEZE_SCRIPT,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338cc685",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31077a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce9da5d",
   "metadata": {},
   "source": [
    "# 11. Conversion to TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da00b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203bc62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(\n",
    "    os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d354226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb64b8e",
   "metadata": {},
   "source": [
    "# 12. Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a404605",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f77c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(\n",
    "    TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b7071",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c75b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f15d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c099cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,300,300,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe2e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc2d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb0d82",
   "metadata": {},
   "source": [
    "# 13. Zip and Export Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d3889",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d159d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odwtf",
   "language": "python",
   "name": "odwtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
